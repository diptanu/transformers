{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Example shapes for tensors\n",
    "batch_size = 2\n",
    "num_heads = 4\n",
    "seq_len = 5\n",
    "head_dim = 64\n",
    "\n",
    "# Example input tensors\n",
    "query_states = torch.randn(batch_size, num_heads, seq_len, head_dim)\n",
    "key_states = torch.randn(batch_size, num_heads, seq_len, head_dim)\n",
    "value_states = torch.randn(batch_size, num_heads, seq_len, head_dim)\n",
    "attention_mask = None\n",
    "\n",
    "# map to bf16\n",
    "import torch\n",
    "query_states = query_states.to(torch.bfloat16).cuda()\n",
    "key_states = key_states.to(torch.bfloat16).cuda()\n",
    "value_states = value_states.to(torch.bfloat16).cuda()\n",
    "\n",
    "# Using scaled_dot_product_attention\n",
    "attn_output_sdpa = F.scaled_dot_product_attention(\n",
    "    query_states,\n",
    "    key_states,\n",
    "    value_states,\n",
    "    attn_mask=attention_mask,\n",
    "    dropout_p=0,  # Example dropout value\n",
    "    is_causal=False  # Assuming non-causal attention for simplicity\n",
    ")\n",
    "\n",
    "# Manual attention implementation\n",
    "dk = query_states.size(-1)\n",
    "scores = torch.matmul(query_states, key_states.transpose(-2, -1)) / torch.sqrt(torch.tensor(dk, dtype=torch.float32))\n",
    "\n",
    "# Apply the mask\n",
    "if attention_mask is not None:\n",
    "    scores += attention_mask\n",
    "\n",
    "# Softmax\n",
    "attention_weights = F.softmax(scores, dim=-1)\n",
    "\n",
    "# Weighted sum\n",
    "attn_output_manual = torch.matmul(attention_weights, value_states)\n",
    "\n",
    "from flash_attn import flash_attn_func\n",
    "attn_output_flash = flash_attn_func(\n",
    "    query_states.transpose(1,2), key_states.transpose(1,2), value_states.transpose(1,2), 0, softmax_scale=None, causal=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 7.0312e-02, -1.4453e-01,  1.4844e+00,  ..., -1.9727e-01,\n",
       "            1.4160e-01,  4.1211e-01],\n",
       "          [ 5.4688e-01,  1.8457e-01,  1.5547e+00,  ...,  4.1016e-02,\n",
       "           -2.4121e-01,  5.0391e-01],\n",
       "          [ 8.8281e-01,  7.4219e-02,  1.7500e+00,  ..., -1.3672e-01,\n",
       "            6.1035e-04,  2.9102e-01],\n",
       "          [ 5.8594e-01, -3.7695e-01,  1.7891e+00,  ..., -4.0430e-01,\n",
       "            1.2109e+00, -8.6975e-04],\n",
       "          [ 1.0312e+00, -4.7070e-01,  1.9922e+00,  ..., -5.3125e-01,\n",
       "            1.4844e+00, -1.1292e-02]],\n",
       "\n",
       "         [[-2.2266e-01, -5.4688e-02, -5.2490e-02,  ..., -2.7734e-01,\n",
       "            1.2256e-01,  6.6406e-01],\n",
       "          [ 2.9297e-03,  1.6309e-01, -1.4551e-01,  ..., -3.2617e-01,\n",
       "            6.6406e-02,  4.6875e-01],\n",
       "          [ 3.2812e-01,  6.4453e-02, -9.3262e-02,  ..., -5.3516e-01,\n",
       "           -3.1641e-01,  4.9219e-01],\n",
       "          [ 4.9023e-01,  1.2891e-01, -3.6328e-01,  ..., -2.6758e-01,\n",
       "           -3.2617e-01,  7.1094e-01],\n",
       "          [-3.7109e-01, -9.4238e-02,  1.6602e-01,  ..., -5.7031e-01,\n",
       "            1.7090e-01,  4.2773e-01]],\n",
       "\n",
       "         [[ 7.5000e-01, -9.1016e-01, -7.9590e-02,  ...,  2.5000e-01,\n",
       "            4.9609e-01,  3.0029e-02],\n",
       "          [ 5.3516e-01, -9.1797e-01, -2.3047e-01,  ..., -3.4424e-02,\n",
       "            4.3555e-01, -5.9814e-02],\n",
       "          [ 6.1328e-01, -7.6953e-01, -2.6367e-01,  ..., -5.2734e-01,\n",
       "            5.1562e-01, -1.4355e-01],\n",
       "          [ 3.8086e-01, -8.9062e-01, -3.4375e-01,  ..., -8.8867e-02,\n",
       "            3.9844e-01,  4.1016e-02],\n",
       "          [ 1.0840e-01, -9.0234e-01, -6.1328e-01,  ..., -7.1875e-01,\n",
       "            4.9219e-01, -6.6406e-01]],\n",
       "\n",
       "         [[-2.2656e-01,  7.4219e-01, -1.1230e-01,  ..., -2.9297e-01,\n",
       "            6.5918e-02, -6.7578e-01],\n",
       "          [ 9.7656e-02,  5.3125e-01, -2.6758e-01,  ...,  1.0559e-02,\n",
       "           -6.1328e-01, -1.0078e+00],\n",
       "          [-2.2949e-02,  7.5781e-01,  1.7944e-02,  ..., -1.9141e-01,\n",
       "           -7.5000e-01, -6.4453e-01],\n",
       "          [ 1.1084e-01,  3.3984e-01, -2.6172e-01,  ...,  1.2268e-02,\n",
       "           -3.0273e-01, -1.3750e+00],\n",
       "          [-2.9883e-01,  9.0625e-01, -2.4316e-01,  ..., -3.2031e-01,\n",
       "            1.1084e-01, -4.0820e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 3.0078e-01,  1.4922e+00, -9.5825e-03,  ..., -5.8203e-01,\n",
       "            5.9766e-01,  7.3828e-01],\n",
       "          [ 3.2031e-01,  1.0859e+00, -9.8145e-02,  ..., -8.7109e-01,\n",
       "            1.7773e-01,  7.5000e-01],\n",
       "          [ 2.4219e-01,  8.5547e-01,  1.9043e-02,  ..., -4.1992e-01,\n",
       "           -4.7656e-01,  3.0859e-01],\n",
       "          [ 3.1250e-02,  4.6484e-01,  1.6016e-01,  ..., -5.3125e-01,\n",
       "           -9.5703e-01,  4.1211e-01],\n",
       "          [ 3.2227e-02,  3.5156e-01,  1.0645e-01,  ..., -7.6562e-01,\n",
       "           -1.0859e+00,  5.9766e-01]],\n",
       "\n",
       "         [[ 2.8711e-01,  2.8687e-02,  9.0625e-01,  ...,  1.4062e-01,\n",
       "            2.3633e-01,  6.9922e-01],\n",
       "          [ 1.3359e+00, -3.3984e-01,  1.4844e+00,  ...,  1.1914e-01,\n",
       "            7.5781e-01,  9.0625e-01],\n",
       "          [-3.3594e-01,  8.5156e-01, -1.4453e-01,  ..., -1.6992e-01,\n",
       "            2.2266e-01,  1.0400e-01],\n",
       "          [ 1.0156e-01,  2.6172e-01,  6.2891e-01,  ...,  3.9551e-02,\n",
       "            1.7383e-01,  5.0391e-01],\n",
       "          [-2.6245e-03,  5.8594e-01,  4.5654e-02,  ...,  2.9688e-01,\n",
       "            6.7969e-01,  6.0156e-01]],\n",
       "\n",
       "         [[ 2.7930e-01,  4.6094e-01,  8.0078e-01,  ...,  4.9023e-01,\n",
       "           -9.8828e-01,  1.2354e-01],\n",
       "          [-1.3379e-01,  5.6250e-01,  3.7109e-01,  ...,  1.8652e-01,\n",
       "           -5.1172e-01, -7.9297e-01],\n",
       "          [ 2.7832e-02,  3.3789e-01,  2.5586e-01,  ...,  6.3281e-01,\n",
       "           -6.2500e-01,  7.3730e-02],\n",
       "          [ 6.5430e-02,  4.5508e-01,  2.0020e-01,  ...,  6.5234e-01,\n",
       "           -5.6250e-01, -6.2988e-02],\n",
       "          [ 3.5547e-01,  6.4453e-01,  6.3281e-01,  ...,  7.5781e-01,\n",
       "           -7.8906e-01, -9.3750e-02]],\n",
       "\n",
       "         [[ 2.4707e-01,  1.3379e-01, -1.9824e-01,  ...,  5.5859e-01,\n",
       "            6.9531e-01,  2.5195e-01],\n",
       "          [ 1.1658e-02,  4.3457e-02,  2.0508e-01,  ..., -2.6562e-01,\n",
       "            9.8047e-01,  1.1953e+00],\n",
       "          [-1.2695e-01,  2.9785e-02,  4.3750e-01,  ..., -7.1875e-01,\n",
       "            9.9609e-01,  1.7656e+00],\n",
       "          [ 2.1875e-01,  3.1433e-03,  3.3691e-02,  ...,  2.7734e-01,\n",
       "            7.5781e-01,  1.8164e-01],\n",
       "          [ 1.1426e-01, -3.0078e-01,  5.9766e-01,  ..., -4.4922e-02,\n",
       "            2.8906e-01, -1.8457e-01]]]], device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 5, 64])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output_sdpa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0',\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output_flash.transpose(1,2)-attn_output_sdpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
